<p align="center"><h1 align="center">APPLYBN</h1></p>
<p align="center">
	<img src="https://img.shields.io/github/license/Anaxagor/applybn?style=default&logo=opensourceinitiative&logoColor=white&color=blue" alt="license">
</p>
<p align="center">Built with the tools and technologies:</p>
<p align="center">
	<img src="https://img.shields.io/badge/Python-3776AB.svg?style=default&logo=Python&logoColor=white"alt="Python">
	<img src="https://img.shields.io/badge/GitHub%20Actions-2088FF.svg?style=default&logo=GitHub-Actions&logoColor=white"alt="GitHub%20Actions">
</p>
<br>

applybn is an open-source multi-purpose framework based on Bayesian networks and Causal models.
It introduces data analysis based on understandable and interpretable algorithms of Bayesian networks and causal models.
![image](https://github.com/user-attachments/assets/996f8e5a-1742-4849-a64f-58b97a4cf17d)

## Key Features
### 1. **Anomaly Detection in time-series and tabular data**
#### **Tabular data**
   - The method combines detection based on Bayesian network conditional distributions and proximity-based scoring.
   - The method allows capturing both density outliers and outliers generated by violation of dependencies between features. 
#### **Time series**
   -  The method identifies outliers in multivariate time series by leveraging dynamic Bayesian networks (DBNs) to model temporal and cross-variable dependencies.
   -  Its key strengths lie in capturing complex temporal interdependencies, automating outlier classification through adaptive score-analysis strategies. 
### 2. **Synthetic Data Generation**
   - The framework includes methods for generating synthetic training data when class imbalance is detected in the dataset. Using hybrid Bayesian networks (with Gaussian mixture models), it generates balanced synthetic data, improving model training outcomes.
   - The method allows us to account for interactions between variables, which improves the quality of the synthetics.

### 3. **Features Selection and Extraction**
#### **Causal effect based features selection**
   - This method quantifies causal effects via information theory and post-nonlinear models, automatically selecting features with non-zero causal impact on key performance indicators (KPIs) by analyzing uncertainty reduction in entropy.
   - The method excels in interpretability and stability by prioritizing causal relationships, avoids manual threshold tuning, and performs reliably even with limited or nonlinear industrial data, enhancing soft sensor robustness.
#### **Normalized MI based features selection**
   - The method combines feature selection with Meek rules to identify Markov blankets, using mutual information to retain nodes with significant dependencies while pruning irrelevant or redundant features in Bayesian networks.
   - Its key advantages include efficient handling of high-dimensional data by focusing on local structures, improved accuracy over traditional methods.
#### **Bayesian networks based features extraction**
   - The method operates by inferring conditional dependencies between features using Bayesian networks and appending probabilistic parameters (λ) representing these relationships to the original dataset.
   - Its advantages include enhanced classification accuracy across diverse domains, reduced reliance on prior knowledge, and low computational complexity, enabling robust and interpretable feature enrichment without domain-specific constraints.

### 4. **Explainable Analysis**
#### **Causal Analysis for Machine Learning Models**
   - The method of analyzing model components - a structural causal model (SCM) is built to analyze deep learning models, allowing for the pruning of unimportant parts (e.g., filters in CNNs) by evaluating their causal importance.
   - The method of explaining data impact on predictions allows for causal inference between features and the model’s confidence scores. By calculating the **Average Causal Effect (ACE)**, it helps identify which features significantly influence model uncertainty, providing valuable insights for improving or debugging models.

### 5. **Scikit-learn compatible**
All the estimators and data transformers are scikit-learn compatible.

## Installation

To get started with applybn, clone the repository and install the required dependencies.

```bash
git clone https://github.com/Anaxagor/applybn.git
cd applybn
poetry install
```

## Help and Support

### Documentation with examples

The documentation with examples can be found [here](https://anaxagor.github.io/applybn/).

### Communitcation

Feel free to create new [issues](https://github.com/Anaxagor/applybn/issues).
If you have questions or suggestions, you can contact us at the following address: ideeva@itmo.ru (Irina Deeva) 

### Contributing

Contributions to applybn are welcome! If you’re interested in improving any of the features or testing new branches, please see the [How to contribute](https://anaxagor.github.io/applybn/development/contributing/) section of the documentation.

### License

applybn is distributed under the MIT License. See the `LICENSE` file for more information.

## Citation

```bibtex
@software{applybn,
  author = {Irina Deeva},
  title = {applybn},
  url = {https://github.com/Anaxagor/applybn},
  version = {0.1.0},
  date = {2025-05-03},
}
```

## Acknowledgement
The project is supported by [FASIE](https://fasie.ru/) - Foundation for Assistance to Small Innovative Enterprises.
