# CausalCNNExplainer: Математическое обоснование

## Обзор
[`CausalCNNExplainer`](../../api/explainable/cnn_filter_importance.md) реализует подход на основе каузального вывода для понимания сверточных нейронных сетей,
как описано в статье
[Explaining Deep Learning Models using Causal Inference, T. Narendra и др.](https://arxiv.org/pdf/1811.04376).
Этот модуль рассматривает фильтры CNN как переменные в каузальном графе, что позволяет измерять
важность фильтров с помощью моделирования структурными уравнениями, а не традиционными подходами на основе корреляции.

## Математическая основа

### Каузальное представление фильтров CNN
Модуль представляет фильтры CNN как узлы в направленном ациклическом графе (DAG),
где ребра представляют каузальные связи между фильтрами в последовательных слоях:

$$
G = (V, E)
$$

где $V$ — это множество фильтров по всем слоям, а $E$ представляет каузальные связи между ними.

### Моделирование структурными уравнениями
Для каждого фильтра $i$ в слое $l$ его активация $F_i^l$ моделируется как функция
его родительских фильтров из предыдущего слоя:

$$F_i^l = f_i(\{F_j^{l-1} | j \in \text{parents}(i)\}) + \epsilon_i$$

Модуль реализует это с помощью линейной регрессии, где выход каждого фильтра
предсказывается на основе выходов его родительских фильтров:

$$F_i^l = \beta_0 + \sum_{j \in \text{parents}(i)} \beta_j \cdot F_j^{l-1} + \epsilon_i$$

### Расчет важности фильтра
Каузальная важность фильтра определяется абсолютными значениями его коэффициентов регрессии
при предсказании всех дочерних фильтров в следующем слое:

$$\text{Importance}(F_j^l) = \sum_{i \in \text{children}(j)} |\beta_{j \rightarrow i}|$$

где $\beta_{j \rightarrow i}$ — это коэффициент регрессии, отражающий, насколько
фильтр $j$ в слое $l$ влияет на фильтр $i$ в слое $l+1$.

### Стратегия прунинга фильтров
Модуль использует эти оценки важности для прунинга, удаляя фильтры с наименьшим каузальным влиянием:

$$\text{PruneSet} = \{F_j^l | \text{Importance}(F_j^l) \leq \text{threshold}_l\}$$

где $\text{threshold}_l$ определяется желаемым процентом прунинга.

## Применения

Этот каузальный подход к интерпретации CNN предлагает:

1. **Интерпретируемый прунинг** - удаляет фильтры на основе каузального влияния, а не величины или дисперсии
2. **Визуализация тепловых карт** - показывает, какие области изображения каузально влияют на решения модели
3. **Взаимосвязи фильтров** - предоставляет понимание зависимостей между фильтрами в разных слоях

Метод демонстрирует, что прунинг на основе каузальной важности
обычно лучше сохраняет точность модели, чем случайный прунинг,
поскольку он выявляет и сохраняет фильтры с самым сильным каузальным влиянием на выход сети.

## Пример

``` py title="examples/explainable/cnn_filter_importance.py"
--8<-- "examples/explainable/cnn_filter_importance.py"
```
