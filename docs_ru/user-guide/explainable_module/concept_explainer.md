# ConceptCausalExplainer: Математическое обоснование

## Обзор
[`ConceptCausalExplainer`](../../api/explainable/concepts_causal.md) реализует новый подход к
интерпретации моделей через каузальный анализ на уровне концептов,
как описано в статье
["Concept-Level Model Interpretation From the Causal Aspect"](https://ieeexplore.ieee.org/abstract/document/9904301).
Вместо анализа важности отдельных признаков, этот модуль выявляет высокоуровневые концепты
в данных и оценивает их каузальное влияние на поведение модели,
предлагая интерпретируемость, которая соответствует понятным для человека концептам.

## Математическая основа

### Идентификация и извлечение концептов
Модуль использует двухэтапный подход к обнаружению концептов:

1. **Обнаружение концептов на основе кластеризации**: Пространство данных разделяется с помощью кластеризации KMeans:

   \( C_i = \{x_j \in D \mid \arg\min_k \|x_j - \mu_k\|^2 = i\} \)

   где:

   - $C_i$ представляет кластер $i$,
   - $D$ — это набор данных для обнаружения,
   - $\mu_k$ — это центроиды кластеров.

&nbsp;2. **Дискриминационная валидация концептов**: Каждый кластер валидируется путем обучения линейного SVM:

   \( S_i(x) = \text{sign}(w_i^T x + b_i) \)

   Кластер считается валидным концептом, если его можно отличить от естественного набора данных с AUC > порога.

### Представление в пространстве концептов
Пространство признаков преобразуется в пространство концептов:
\( A(x) = [A_1(x), A_2(x), ..., A_m(x)] \)
где $A_i(x) = 1$, если $x$ принадлежит концепту $i$, и 0 в противном случае.

### Оценка каузального эффекта
Для бинарного исхода $L_f$ каузальный эффект концепта $A_i$ оценивается с помощью:
\(\tau_i = \mathbb{E}[L_f \mid do(A_i = 1)] - \mathbb{E}[L_f \mid do(A_i = 0)]\)

Для непрерывных исходов, таких как уверенность модели, используется фреймворк Double Machine Learning:
\(\tau_i(x) = \mathbb{E}[Y \mid do(A_i = 1), X = x] - \mathbb{E}[Y \mid do(A_i = 0), X = x]\)

где $Y$ — интересующий исход (например, уверенность модели), а $X$ — другие концепты, выступающие в качестве контрольных переменных.

## Применения

Этот подход предлагает несколько преимуществ:

1. **Интерпретируемость**: Концепты соответствуют понятным для человека паттернам в данных
2. **Каузальное понимание**: Оценки каузальных эффектов, а не корреляций
3. **Диагностическая сила**: Выявляет, какие концепты каузально влияют на поведение модели
4. **Переносимость**: Концепты могут применяться к разным моделям на одних и тех же данных

Понимая каузальные связи между концептами и поведением модели,
пользователи могут принимать более обоснованные решения об улучшениях модели, сборе данных и стратегиях инжиниринга признаков.

## Пример

``` py title="examples/explainable/concept_explainer.py"
--8<-- "examples/explainable/concept_explainer.py"
```
